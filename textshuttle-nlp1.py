# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/170BPR3OYH6_3wi4b1XtgucYU1y0XqcGW
"""

#!/usr/bin/env python3

from pathlib import Path


class Corpus:

    def __init__(self, path: Path):
        """
        Load segments from a file, one per line.
        """
        with path.open(encoding='utf-8') as corpus:
            self.segments = [s.strip('\n') for s in corpus]

    def filter(self, min_alpha: float = 0.5):
        """
        Discard all segments with too few alphabetical characters.

        Keep only segments where at least `min_alpha` of the
        characters are alphabetic.

        Examples for min_alpha == 0.5:
            "So."      # keep
            "¡Sí!"     # keep
            "Ja!!!"    # discard
            "123.5"    # discard
        """
        pass  # TODO: Task 1

    def normalize(self):
        """
        Replace fancy quotes like « » „ “ ” with ASCII quotes (").
        """
        pass  # TODO: Task 1

    def split(self, language: str = 'en'):
        """
        Split up segments containing multiple sentences using an online API.
        Remove any leading and trailing whitespace.

        Example:
            Before: self.segments = ["Wie geht's?", "Ausgezeichnet. Und dir?"]
            After:  self.segments = ["Wie geht's?", "Ausgezeichnet.", "Und dir?"]
        """
        pass  # TODO: Task 2


# TODO: Task 3

#!/usr/bin/env python3

from pathlib import Path


class Corpus:

    def __init__(self, path: Path):
        """
        Load segments from a file, one per line.
        """
        with path.open(encoding='utf-8') as corpus:
            self.segments = [s.strip('\n') for s in corpus]

    def filter(self, min_alpha: float = 0.5):
        """
        Discard all segments with too few alphabetical characters.

        Keep only segments where at least `min_alpha` of the
        characters are alphabetic.

        Examples for min_alpha == 0.5:
            "So."      # keep
            "¡Sí!"     # keep
            "Ja!!!"    # discard
            "123.5"    # discard
        """
        new_segments = [] # segments after filtering
        for s in self.segments:
            # iterate over all segments
            alpha_count = 0 # count of alphabetic characters
            for i in s:
                if i.isalpha(): # whether character i is alpha
                    alpha_count += 1
            if alpha_count / len(s) >= min_alpha:
                new_segments.append(s)

        return new_segments  # TODO: Task 1

    def normalize(self):
        """
        Replace fancy quotes like « » „ “ ” with ASCII quotes (").
        """

        new_segments = [] # segments after filtering
        for s in self.segments:
            # iterate over all segments
            alpha_count = 0 # count of alphabetic characters
            new_s = "" # new segment, initialized to an empty string
            for i in s: #we need a range to input i into s
                if i in ["«", "»", "„", "“", "”"]: # whether character i is a fancy quote
                    new_s = new_s + '"'
                else:
                    new_s = new_s + i
            new_segments.append(new_s)

        return new_segments  # TODO: Task 1

    def split(self, language: str = 'en'):
        """
        Split up segments containing multiple sentences using an online API.
        Remove any leading and trailing whitespace.

        Example:
            Before: self.segments = ["Wie geht's?", "Ausgezeichnet. Und dir?"]
            After:  self.segments = ["Wie geht's?", "Ausgezeichnet.", "Und dir?"]
        """
        pass  # TODO: Task 2


# TODO: Task 3

import requests

r = requests.post(
    url='https://stg.tait.ts.mt/api/v2/split_sentences', 
    headers={'accept': 'application/json', 'Content-type':'application/json'},
    data=r'{"text": "Winston went up the stairs.   In the hallway, it smelled like boiled cabbage and damp floor mats.\n It was disgusting!", "language": "en"}', 
    )

import json

eval((r.content))

